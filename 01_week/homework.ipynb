{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pa\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorise = DictVectorizer()\n",
    "linear_regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path to the data directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "DATA_PATH = os.path.join(PARENT_DIRECTORY, '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "def read_data(data):\n",
    "    if data.endswith('.parquet'):\n",
    "        data = pa.read_table(data)\n",
    "        df = data.to_pandas() # converting to pandas df\n",
    "        df.columns = df.columns.str.lower()\n",
    "        return df\n",
    "    elif data.endswith('.csv'):\n",
    "        df = pd.read_csv(data)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        return 'Not valid format'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the standard deviation of the pick and drop time in minutes\n",
    "def standard_deviation(data):\n",
    "    data['duration'] = pd.to_datetime(data['tpep_dropoff_datetime']) - pd.to_datetime(data['tpep_pickup_datetime'])\n",
    "    # Convert duration to total seconds\n",
    "    data['duration'] = data['duration'].dt.total_seconds()\n",
    "    # Convert seconds to hours and minutes\n",
    "    data['duration'] = data['duration'] / 60\n",
    "    # Standard deviation\n",
    "    return data, data['duration'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(data):\n",
    "    data_outliers = data[(data['duration']>=1)&(data['duration']<=60)]\n",
    "    return data_outliers, (data_outliers.shape[0] / data.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "def one_hot_encoding(df, choice):\n",
    "    # Converting pick up and drop off location id into strings\n",
    "    df['pulocationid'] = df['pulocationid'].astype(str)\n",
    "    df['dolocationid'] = df['dolocationid'].astype(str)\n",
    "\n",
    "    # Converting DataFrame into a list of dictionaries\n",
    "    df_dict = df[['pulocationid', 'dolocationid']].to_dict(orient='records')\n",
    "\n",
    "    if choice == 0:\n",
    "        X_train = vectorise.fit_transform(df_dict)\n",
    "        return X_train\n",
    "    elif choice == 1:\n",
    "        X_val = vectorise.transform(df_dict)\n",
    "        return X_val\n",
    "    else:\n",
    "        return 'Enter Choice 0 or 1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMSE function\n",
    "def rmse(y_, y_pred):\n",
    "    return root_mean_squared_error(y_, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data, X_train):\n",
    "    y_train = data['duration'].values\n",
    "\n",
    "    linear_regression.fit(X_train, y_train)\n",
    "    y_prediction = linear_regression.predict(X_train)\n",
    "\n",
    "    # Calculate the Root Mean Square Error\n",
    "    RMSE = rmse(y_train, y_prediction)\n",
    "    return y_train, y_prediction, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(df_val, X_val):\n",
    "    y_val = df_val['duration'].values\n",
    "    y_prediction = linear_regression.predict(X_val)\n",
    "    RMSE = rmse(y_val, y_prediction)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Downloading the data\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\\\n",
    "Download the data for January and February 2023.\\\n",
    "Read the data for January. How many columns are there?\\\n",
    "a) 16 \\\n",
    "b) 17 \\\n",
    "c) 18 \\\n",
    "d) 19 \n",
    "\n",
    "# Answer : d) 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January Data Shape = (3066766, 19)\n",
      "February Data Shape = (2913955, 19)\n"
     ]
    }
   ],
   "source": [
    "# File Name\n",
    "january_file_name = 'yellow_tripdata_2023-01.parquet'\n",
    "february_file_name = 'yellow_tripdata_2023-02.parquet'\n",
    "\n",
    "# Join January data path\n",
    "january_data_path = os.path.join(DATA_PATH, january_file_name)\n",
    "# Join February data path\n",
    "february_data_path = os.path.join(DATA_PATH, february_file_name)\n",
    "\n",
    "# READ JANUARY DATA\n",
    "df_train = read_data(january_data_path)\n",
    "# READ FEBRUARY DATA\n",
    "df_val = read_data(february_data_path)\n",
    "\n",
    "print(f'January Data Shape = {df_train.shape}')\n",
    "print(f'February Data Shape = {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Computing duration\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\\\n",
    "What's the standard deviation of the trips duration in January?\\\n",
    "a) 32.59\\\n",
    "b) 42.59\\\n",
    "c) 52.59\\\n",
    "d) 62.59\n",
    "\n",
    "# Answer: b) 42.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Pick and Drop time for the month of January (time in minutes) 42.59435124195458\n",
      "January Data Shape after adding column minutes= (3066766, 20)\n"
     ]
    }
   ],
   "source": [
    "df_train, january_duriation_std_dev = standard_deviation(df_train)\n",
    "print('Standard Deviation of Pick and Drop time for the month of January (time in minutes)', january_duriation_std_dev)\n",
    "print(f'January Data Shape after adding column minutes= {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Pick and Drop time for the month of FEbruary (time in minutes) 42.84210176105113\n",
      "February Data Shape after adding column minutes = (2913955, 20)\n"
     ]
    }
   ],
   "source": [
    "df_val, february_duriation_std_dev = standard_deviation(df_val)\n",
    "print('Standard Deviation of Pick and Drop time for the month of FEbruary (time in minutes)', february_duriation_std_dev)\n",
    "print(f'February Data Shape after adding column minutes = {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).  \\\n",
    "What fraction of the records left after you dropped the outliers?  \\\n",
    "a) 90%  \\\n",
    "b) 92%  \\\n",
    "c) 95%  \\\n",
    "d) 98% \n",
    "\n",
    "# Answer: d) 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of the records left after dropping the outliers =  98.1220282212598\n",
      "January Data Shape after removing outliers= (3009173, 20)\n"
     ]
    }
   ],
   "source": [
    "df_train, jan_records_left = outliers(df_train)\n",
    "print('Fraction of the records left after dropping the outliers = ', jan_records_left)\n",
    "print(f'January Data Shape after removing outliers= {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of the records left after dropping the outliers =  98.00944077722545\n",
      "February Data Shape after removing outliers = (2855951, 20)\n"
     ]
    }
   ],
   "source": [
    "df_val, feb_records_left = outliers(df_val)\n",
    "print('Fraction of the records left after dropping the outliers = ', feb_records_left)\n",
    "print(f'February Data Shape after removing outliers = {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "1) Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "2) Fit a dictionary vectorizer\n",
    "3) Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "a) 2  \\\n",
    "b) 155  \\\n",
    "c) 345  \\\n",
    "d) 515  \\\n",
    "e) 715\n",
    "\n",
    "# Answer: d) 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************\n",
      "Feature Matrix size = (3009173, 515)\n"
     ]
    }
   ],
   "source": [
    "# Fit DictVectorizer and transform January data\n",
    "X_train = one_hot_encoding(df_train, choice=0)\n",
    "print('*******************************************')\n",
    "print(f'Feature Matrix size = {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE\n",
    "\n",
    "RMSE = sqrt [(Σ(Pi – Oi)²) / n]\n",
    "\n",
    "Where \\\n",
    "Pi==> Predicted Value  \\\n",
    "Oi==> Observed Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "1) Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "2) Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "a) 3.64 \\\n",
    "b) 7.64  \\\n",
    "c) 11.64  \\\n",
    "d) 16.64\n",
    "\n",
    "# Answer: b) 7.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Root Mean Square Error = 7.649262092523899\n"
     ]
    }
   ],
   "source": [
    "y_train, y_prediction, RMSE = training(df_train, X_train)\n",
    "print(f'Training Root Mean Square Error = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \\\n",
    "What's the RMSE on validation?  \\\n",
    "a) 3.81  \\\n",
    "b) 7.81  \\\n",
    "c) 11.81  \\\n",
    "d) 16.81\n",
    "\n",
    "# Answer: b) 7.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform February data using the fitted DictVectorizer\n",
    "X_val = one_hot_encoding(df_val, choice=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 7.811817680839882\n"
     ]
    }
   ],
   "source": [
    "RMSE = evaluation(df_val, X_val)\n",
    "print(f'Validation RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken = 76.92450189590454\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f'Total time taken = {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
